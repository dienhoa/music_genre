{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34fbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torchaudio\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import librosa\n",
    "import kornia\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7653af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07cdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/ubuntu/.kaggle/kaggle-pog-series-s01e02/train.csv')\n",
    "df_test = pd.read_csv('/home/ubuntu/.kaggle/kaggle-pog-series-s01e02/test.csv')\n",
    "submission = pd.read_csv('/home/ubuntu/.kaggle/kaggle-pog-series-s01e02/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963abb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/')\n",
    "test_path = Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/')\n",
    "# train_path = Path('/home/ubuntu/.kaggle/rescale/spectograms/train/')\n",
    "# test_path = Path('/home/ubuntu/.kaggle/rescale/spectograms/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ba9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = get_image_files(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6efd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#19909) [Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/006638.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/000618.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/016641.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/023943.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/023478.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/016103.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/005110.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/023831.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/000200.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/007218.png')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566ebff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(filename):\n",
    "    resample_name = filename.stem + '.ogg'\n",
    "    return df_train[df_train['filename']==resample_name]['genre'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0bb6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluded unusual music thanks to this thread: https://www.kaggle.com/c/kaggle-pog-series-s01e02/discussion/312842\n",
    "def get_items(path): \n",
    "    excluded_files = [\"010449.png\" , \n",
    "                      \"005589.png\" , \n",
    "                      \"004921.png\", \n",
    "                      \"019511.png\" , \n",
    "                      \"013375.png\" , \n",
    "                      \"024247.png\", \n",
    "                      \"024156.png\"]\n",
    "    items = get_image_files(path)\n",
    "    items = [item for item in items if item.name not in excluded_files]\n",
    "    \n",
    "    ## For fast iteration\n",
    "#     items = [item for item in items if get_y(item) in ['Punk', 'Rock']]\n",
    "    random.shuffle(items)\n",
    "#     items.shuffle()\n",
    "    return L(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5889a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_FFT = 2048\n",
    "# HOP_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1444cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_spectrogram(filename):\n",
    "#     audio, sr = torchaudio.load(filename)\n",
    "    \n",
    "#     audio = audio.squeeze()\n",
    "#     audio, index = librosa.effects.trim(audio, frame_length=1024, hop_length=256)  \n",
    "#     audio = audio.unsqueeze(0)\n",
    "        \n",
    "#     specgram = torchaudio.transforms.MelSpectrogram(sample_rate=sr, \n",
    "#                                                     n_fft=N_FFT, \n",
    "#                                                     win_length=N_FFT, \n",
    "#                                                     hop_length=HOP_LEN,\n",
    "#                                                     center=True,\n",
    "#                                                     pad_mode=\"reflect\",\n",
    "#                                                     power=2.0,\n",
    "#                                                     norm='slaney',\n",
    "#                                                     onesided=True,\n",
    "#                                                     n_mels=128,\n",
    "#                                                     mel_scale=\"htk\"\n",
    "#                                                    )(audio)[0]\n",
    "#     specgram = torchaudio.transforms.AmplitudeToDB()(specgram)\n",
    "#     specgram = specgram - specgram.min()\n",
    "#     specgram = specgram/specgram.max()*255\n",
    "    \n",
    "    \n",
    "#     return specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58465de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = train_files[0]\n",
    "# spec_default = create_spectrogram(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb0d48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = get_items(train_path)\n",
    "labels = [get_y(item) for item in items]\n",
    "count = Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568ce4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = get_items(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ede7502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5076) [Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/000157.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/011703.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/004099.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/017496.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/015293.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/020178.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/009283.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/013417.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/018378.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/test/024413.png')...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98cfa172",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(test_items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3d8c2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 1293, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7b9ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627abd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf07246",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_kfold=[]\n",
    "for _, val_idx in kf.split(np.array(items), labels):\n",
    "    splits = IndexSplitter(val_idx)\n",
    "    split = splits(items)\n",
    "    split_list = [split[0], split[1]]\n",
    "    splits_kfold.append(split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ef646a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(#17058) [0,1,2,3,4,5,6,7,8,9...],\n",
       "  (#2844) [12,15,31,75,85,99,102,124,133,140...]],\n",
       " [(#17059) [1,2,3,4,9,11,12,13,14,15...],\n",
       "  (#2843) [0,5,6,7,8,10,25,26,29,45...]],\n",
       " [(#17059) [0,1,3,4,5,6,7,8,9,10...],\n",
       "  (#2843) [2,11,14,18,30,32,33,40,46,52...]],\n",
       " [(#17059) [0,2,3,4,5,6,7,8,9,10...],\n",
       "  (#2843) [1,20,22,24,28,35,37,42,51,69...]],\n",
       " [(#17059) [0,1,2,3,5,6,7,8,9,10...],\n",
       "  (#2843) [4,19,21,27,48,50,53,57,58,61...]],\n",
       " [(#17059) [0,1,2,3,4,5,6,7,8,10...],\n",
       "  (#2843) [9,13,34,36,38,43,47,65,72,77...]],\n",
       " [(#17059) [0,1,2,4,5,6,7,8,9,10...],\n",
       "  (#2843) [3,16,17,23,39,41,44,59,76,79...]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8958945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_learner(learn, channels=1):\n",
    "    learn.model[0][0][0].in_channels=channels\n",
    "    learn.model[0][0][0].weight = torch.nn.parameter.Parameter(learn.model[0][0][0].weight[:,1,:,:].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8aaea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreid_from_genre(genre):\n",
    "    return int(genre2id[genre2id['genre'] == genre]['genre_id'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34e02417",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_1fold = splits_kfold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2780b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(#17058) [0,1,2,3,4,5,6,7,8,9...],\n",
       "  (#2844) [12,15,31,75,85,99,102,124,133,140...]],\n",
       " [(#17059) [1,2,3,4,9,11,12,13,14,15...],\n",
       "  (#2843) [0,5,6,7,8,10,25,26,29,45...]],\n",
       " [(#17059) [0,1,3,4,5,6,7,8,9,10...],\n",
       "  (#2843) [2,11,14,18,30,32,33,40,46,52...]],\n",
       " [(#17059) [0,2,3,4,5,6,7,8,9,10...],\n",
       "  (#2843) [1,20,22,24,28,35,37,42,51,69...]],\n",
       " [(#17059) [0,1,2,3,5,6,7,8,9,10...],\n",
       "  (#2843) [4,19,21,27,48,50,53,57,58,61...]],\n",
       " [(#17059) [0,1,2,3,4,5,6,7,8,10...],\n",
       "  (#2843) [9,13,34,36,38,43,47,65,72,77...]],\n",
       " [(#17059) [0,1,2,4,5,6,7,8,9,10...],\n",
       "  (#2843) [3,16,17,23,39,41,44,59,76,79...]]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e433",
   "metadata": {},
   "source": [
    "### Test Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926d1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = untar_data(URLs.PETS)\n",
    "\n",
    "# test_imgs = get_image_files(path)\n",
    "\n",
    "# TEST_IMAGE = test_imgs[4]\n",
    "\n",
    "# img = PILImage(PILImage.create(TEST_IMAGE))\n",
    "\n",
    "\n",
    "class ReflectionCrop(RandomCrop):\n",
    "    def encodes(self, x:(Image.Image,TensorBBox,TensorPoint)):\n",
    "        return x.crop_pad(self.size, self.tl, orig_sz=self.orig_sz, pad_mode=PadMode.Reflection)\n",
    "\n",
    "# rsz = ReflectionCrop((375, 100))\n",
    "\n",
    "# img2 = rsz(img, split_idx=0)\n",
    "\n",
    "# img.shape\n",
    "\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8ab39f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#19902) [Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/018077.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/002401.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/023117.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/010941.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/013164.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/005997.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/020891.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/011658.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/010410.png'),Path('/home/ubuntu/.kaggle/spectrograms/spectograms/train/024072.png')...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "799fc3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#17058) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#2844) [12,15,31,75,85,99,102,124,133,140...]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_1fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae0d8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataBlock(DataBlock):\n",
    "    def datasets(self:DataBlock, source, verbose=False, splits=None):\n",
    "        self.source = source                     ; pv(f\"Collecting items from {source}\", verbose)\n",
    "        items = (self.get_items or noop)(source) ; pv(f\"Found {len(items)} items\", verbose)\n",
    "        pv(f\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\", verbose)\n",
    "        return Datasets(items, tfms=self._combine_type_tfms(), splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)\n",
    "    def dataloaders(self, source, path='.', verbose=False, splits=None, **kwargs):\n",
    "        dsets = self.datasets(source, verbose=verbose, splits=splits)\n",
    "        kwargs = {**self.dls_kwargs, **kwargs, 'verbose': verbose}\n",
    "        return dsets.dataloaders(path=path, after_item=self.item_tfms, after_batch=self.batch_tfms, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13cc5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_MP_to_blurMP(model, layer_type_old):\n",
    "    conversion_count = 0\n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            # recurse\n",
    "            model._modules[name] = convert_MP_to_blurMP(module, layer_type_old)\n",
    "\n",
    "        if type(module) == layer_type_old:\n",
    "            layer_old = module\n",
    "            layer_new = kornia.contrib.MaxBlurPool2d(3, True)\n",
    "            model._modules[name] = layer_new\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05ff73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(splits_1fold, nb_epoch=42):\n",
    "    \n",
    "    db = CustomDataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_y=get_y,\n",
    "        item_tfms=[ReflectionCrop(224)],\n",
    "        batch_tfms=aug_transforms(max_rotate=0, max_warp=0,size=224))\n",
    "    \n",
    "    dls = db.dataloaders(items, splits=splits_1fold)\n",
    "    \n",
    "    mixup = MixUp(0.4)\n",
    "    model = xse_resnext50(n_out=19, act_cls=Mish, sa=1, pool=MaxPool, pretrained=False)\n",
    "    model = convert_MP_to_blurMP(model, nn.MaxPool2d)\n",
    "    \n",
    "    learn = Learner(dls, \n",
    "                    model, \n",
    "                    metrics=[accuracy, F1Score(average='micro')], \n",
    "                    loss_func=LabelSmoothingCrossEntropy(eps=0.15), \n",
    "                    opt_func=ranger, \n",
    "                   )\n",
    "    \n",
    "    learn.to_fp16()\n",
    "    \n",
    "#     nchannels = 1\n",
    "#     alter_learner(learn, nchannels)\n",
    "    \n",
    "    learn.fit_flat_cos(nb_epoch, 0.002, cbs=[mixup, CSVLogger(fname=f'history_{int(time.time())}.csv'), ShowGraphCallback()])\n",
    "    \n",
    "#     test_dl = dls.test_dl(test_items)\n",
    "#     preds = learn.get_preds(dl=test_dl)\n",
    "    return None, learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a9baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1' class='' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.38% [1/42 03:17<2:14:38]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.361840</td>\n",
       "      <td>2.195860</td>\n",
       "      <td>0.389944</td>\n",
       "      <td>0.389944</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='249' class='' max='266' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      93.61% [249/266 02:52<00:11 2.2763]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_kfold_learns = []\n",
    "for split_1fold in splits_kfold:\n",
    "    preds_1fold_learns = get_preds(split_1fold)\n",
    "    preds_kfold_learns.append(preds_1fold_learns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2957b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_kfold_learns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad120c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, learn = preds_kfold_learns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dl = learn.dls.test_dl(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "_before_epoch = [event.before_fit, event.before_epoch]\n",
    "_after_epoch  = [event.after_epoch, event.after_fit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def ttacustom(self:Learner, ds_idx=1, dl=None, n=4, item_tfms=None, batch_tfms=None, beta=0.25, use_max=False):\n",
    "    \"Return predictions on the `ds_idx` dataset or `dl` using Test Time Augmentation\"\n",
    "    if dl is None: dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "    if item_tfms is not None or batch_tfms is not None: dl = dl.new(after_item=item_tfms, after_batch=batch_tfms)\n",
    "    try:\n",
    "        self(_before_epoch)\n",
    "        with dl.dataset.set_split_idx(0), self.no_mbar():\n",
    "            if hasattr(self,'progress'): self.progress.mbar = master_bar(list(range(n)))\n",
    "            aug_preds = []\n",
    "            for i in self.progress.mbar if hasattr(self,'progress') else range(n):\n",
    "                self.epoch = i #To keep track of progress on mbar since the progress callback will use self.epoch\n",
    "                preds = self.get_preds(dl=dl, inner=True)[0][None]\n",
    "                aug_preds.append(preds)\n",
    "#                 preds_idx = preds.squeeze().argmax(1)\n",
    "#                 aug_preds.append(preds_idx)\n",
    "#         aug_preds = torch.cat(aug_preds)\n",
    "#         aug_preds = aug_preds.max(0)[0] if use_max else aug_preds.mean(0)\n",
    "#         self.epoch = n\n",
    "#         with dl.dataset.set_split_idx(1): preds,targs = self.get_preds(dl=dl, inner=True)\n",
    "    finally: self(event.after_fit)\n",
    "\n",
    "#     if use_max: return torch.stack([preds, aug_preds], 0).max(0)[0],targs\n",
    "#     preds = (aug_preds,preds) if beta is None else torch.lerp(aug_preds, preds, beta)\n",
    "    return aug_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a71dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_preds = learn.ttacustom(dl=test_dl, n=2, beta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52205b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487430a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e357c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_kfold = [pred_learn[0] for pred_learn in preds_kfold_learns]\n",
    "learns = [pred_learn[1] for pred_learn in preds_kfold_learns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05949d",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, learn in enumerate(learns):\n",
    "    print(i)\n",
    "    learn.export(f'learn_export_{i}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576925a",
   "metadata": {},
   "source": [
    "### Finish test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f03b66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ReflectionCrop -- {'size': (224, 224), 'p': 1.0} -> ToTensor"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.dls.after_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a7c2895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Flip -- {'size': 224, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2d7f833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.transforms.IntToFloatTensor"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntToFloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe21e2fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2016/1621430860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maug_preds_1fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttacustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIntToFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maug_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_preds_1fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2016/2339424278.py\u001b[0m in \u001b[0;36mttacustom\u001b[0;34m(self, ds_idx, dl, n, item_tfms, batch_tfms, beta, use_max)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmbar\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'progress'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;31m#To keep track of progress on mbar since the progress callback will use self.epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0maug_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#                 preds_idx = preds.squeeze().argmax(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mctx_mgrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_not_reduced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx_mgrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mordered_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'missing {event_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnorm_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCancelBatchException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/callback/core.py\u001b[0m in \u001b[0;36mafter_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m\"Save predictions, targets and potentially losses\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_preds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_targs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mto_detach\u001b[0;34m(self, b, cpu, gather)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'to_detach'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mto_detach\u001b[0;34m(b, cpu, gather)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(x, cpu, gather)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorchvideo/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aug_preds = []\n",
    "for learn in learns:\n",
    "    test_dl = learn.dls.test_dl(test_items)\n",
    "    aug_preds_1fold = learn.ttacustom(dl=test_dl, n=20, beta=None, item_tfms=learn.dls.after_item, batch_tfms=IntToFloatTensor)\n",
    "    aug_preds.extend(aug_preds_1fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47ac82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_kfold = [pred_learn[0][0] for pred_learn in preds_kfold_learns]\n",
    "# preds_list = [pred.argmax(axis=1) for pred in preds_kfold]\n",
    "# preds_array = np.array(preds_list)\n",
    "# final_votes = preds_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb28887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9588b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb714f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "668c7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_preds_new = [aug_pred.squeeze().argmax(1) for aug_pred in aug_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "100a4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_votes = stats.mode(torch.vstack(aug_preds_new))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55d05dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 16,  7, ...,  2,  6, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdd9ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_kfold = [pred_learn[0] for pred_learn in preds_kfold_learns]\n",
    "# preds_kfold = [np.array(preds[0]) for preds in preds_kfold]\n",
    "# preds_list = [pred.argmax(axis=1) for pred in preds_kfold]\n",
    "# preds_array = np.array(preds_list)\n",
    "# values, counts = np.unique(preds_array,axis=0, return_counts=True)\n",
    "# Counter(preds_array[:,0]).most_common(1)[0][0]\n",
    "# final_votes = [Counter(preds_array[:,i]).most_common(1)[0][0] for i in range(preds_array.shape[1])]\n",
    "# final_preds = np.array(preds_kfold).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc4ccbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_votes = preds_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe480017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ae80d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission[submission['song_id']==\"024013\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f702f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([140, 5076, 19])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack(aug_preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70863dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5076, 19)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_votes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e8ddc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_idx = final_preds.argmax(axis=1)\n",
    "genre2id = pd.read_csv('/home/ubuntu/.kaggle/kaggle-pog-series-s01e02/genres.csv')\n",
    "songid_preds = {int(file_path.stem):genreid_from_genre(learns[0].dls.vocab[_id]) for file_path, _id in zip(test_items,final_votes)}\n",
    "submission['genre_id'] = submission['song_id'].map(songid_preds)\n",
    "submission['genre_id'].fillna(0, inplace=True)\n",
    "submission.loc[submission['song_id']==22612, 'genre_id'] = 1\n",
    "submission.loc[submission['song_id']==24013, 'genre_id'] = 0\n",
    "\n",
    "submission.genre_id = submission.genre_id.astype(int)\n",
    "submission.to_csv(f\"submission_final_{int(time.time())}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64ad546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>genre_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10207</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21896</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>6427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>16903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>1731</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>12871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>20319</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5078 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  genre_id\n",
       "0        7072         0\n",
       "1       10207        12\n",
       "2       20008         0\n",
       "3       10924         0\n",
       "4       21896         4\n",
       "...       ...       ...\n",
       "5073     6427         3\n",
       "5074    16903         0\n",
       "5075     1731         6\n",
       "5076    12871         0\n",
       "5077    20319        12\n",
       "\n",
       "[5078 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab5cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
